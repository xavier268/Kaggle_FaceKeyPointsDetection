---
title: "5d.corrAverageImg"
output: 
  html_document: 
    toc: yes
---

# Correlating the image vs the average image, to detect shifts or scaling

## Loading the data

We load from the compiled, preformatted data saved earlier :

```{r Loading environement}
load("d.train.RData")
load("im.train.RData")
load("im.test.RData")
load("functions.viewing.RData")
set.seed(24)
ls()
```

## Computing the 'average' image

We will only use complete images.

```{r compute average image}

im.average <- colMeans(im.train[d.train.complete,])
m.plotImage(im.average, kp=d.key.mean)

```


## Correlate 2 sub-images of the same size

Compute correlation :

```{r }
c.corSubImage <- function(im1, im2, xrange=1:96,yrange=1:96, xshift=0, yshift=0){
s1 <- as.vector(matrix(im1,96,96)[xrange,yrange])
s2 <- as.vector(matrix(im2,96,96)[xrange + xshift,yrange + yshift])
return (cor(s1,s2))
}
```

Find best shift values to maximize correlation

* im1 and im2 are vectors of 9296 values
* xrange/yrange define the ranges
* debug = TRUE prodices a cor chart to locate the image shift

```{r}
c.corBestShift <- function(im1, im2, xrange=1:96,yrange=1:96, debug=FALSE) {
  bx <- 0
  by <- 0
  c <- -10000
  if(debug) {p <- matrix(0,96,96)}
  for( x in seq(1 - min(xrange) , 96 - max(xrange))){
    for( y in seq(1 - min(yrange) , 96 - max(yrange))){
      cc <- c.corSubImage(im1,im2,xrange,yrange,x,y)
      if(debug){p[x+48,y+48] <- cc}
      if(cc > c) {
        bx <- x
        by <- y
        c <- cc
      }
    }
  }
  if(debug){
    par(c(3,3))
    image(1:96,1:96,matrix(rev(p),96,96))
    image(1:96,1:96,matrix(rev(im1),96,96))
    image(1:96,1:96,matrix(rev(im2),96,96))
    
    }
  return (list(x=bx,y=by,c=c))
}

```

Let's try on a a few example image :

* original is red,
* average is yellow
* predicted is blue (average + shift)

```{r}
for(i in 1:5) {
  test <- sample(d.train.complete,1)
shift <- c.corBestShift(im.average,im.train[test,] , 10:90,20:80)
m.plotImage(im.train[test,], kp = d.train[test,])
m.plotKeypoints(d.key.mean + rep(c(shift$x, shift$y),15),col = "blue")
m.plotKeypoints(d.key.mean ,col = "yellow")
shift
}

```

And now, on a few test images :

* average is yellow
* predicted is blue (average + shift)

```{r}
for(i in 1:5){
test <- sample(1:1783,1)
shift <- c.corBestShift(im.average,im.test[test,] , 20:80,20:80)
m.plotImage(im.test[test,])
m.plotKeypoints(d.key.mean + rep(c(shift$x, shift$y),15),col = "blue")
m.plotKeypoints(d.key.mean ,col = "yellow")
shift
}
```

Seems like that could work, but clearly need to take into account ratio, rotation, etc ... Or focus on individal aspects, such as eyes and mouth ?

## Interpolating utility for an image (bilinear)

x and y and any real points, but within valid index ranges
imat must be an image matrix, any size.

```{r}
c.interpolateImg <- function(imat, x,y) {
  
  xx <- floor(x)
  yy <- floor(y)
  
  lambda <- x - xx  # 0<= lambda < 1
  mu <- y - yy
  
  if(lambda==0 & mu==0) {
    return (imat[x,y])
  }
  if(lambda == 0) {
    return (
    mu*imat[xx,yy+1]
    +(1-mu)*imat[xx,yy]
    )
  }
  if(mu==0) {
    return (
    (1-lambda)*imat[xx,yy]
    +lambda*imat[xx+1,yy]
    )
  }
  return (
    lambda*mu*imat[xx+1,yy+1]
    +(1-lambda)*mu*imat[xx,yy+1]
    +(1-lambda)*(1-mu)*imat[xx,yy]
    +lambda*(1-mu)*imat[xx+1,yy]
    )
  
}
```

Lets check by zooming in a picture ...

```{r}
imat <- matrix(rev(im.train[1,]),96,96)
image(imat,asp=1.)
imat2 <- matrix(0,133,133)
for(x in 1:133){
  for(y in 1:133){
    imat2[x,y] <- c.interpolateImg(imat,1 + (x-1)*95/132, 1 + (y-1)*95/132)
  }
}
image(imat2, asp=1.)
```

Sounds good.

## Applying a linear transformation to an image

We will apply a linear transformation to the image, defined by a translation vector T and a Rotation/scaling matrix R. R must be a 2x2 invertible matrix.

If X is a 2x1 coordinate vector, the new coordinates are RX + T.

Undefined values are set to the nearest border value.


```{r}
c.transformImg <- function(imat,R,T ){
  size <- nrow(imat)
  imat2 <- matrix(128,size,size)
  
  for(x in 1:size){
    for(y in 1:size) {
      tr <- R %*% matrix(c(x,y),2,1) + T 
      if(all(tr > 1 & tr <= dim(imat2) )) {
        imat2[x,y] <- c.interpolateImg(imat,tr[1],tr[2])
      }
    }
  }
  return (imat2)
}
```

We also define a similar transformation for keyPoints.

```{r}

c.transformKeys <- function(keys,R,T) {
  
  kk <-  rep(0,30)
  for(k in seq(1,29,2)) {
    x <-as.vector(c(keys[k],keys[k+1]), mode="numeric")
    X <- solve(R,x - T)
    kk[k] <- X[1]
    kk[k+1] <- X[2]
  }
  return (kk)
}
```

Testing ...
```{r}
R <- matrix(c(1,1,-1,1),2,2)
T <- matrix(c(45,-15),2,1)
imat <- matrix(im.train[15,],96,96)
m.plotImage(imat,kp=d.key.mean)
m.plotImage(c.transformImg(imat, R, T) , kp=c.transformKeys(d.train[15,],R,T))
R <- matrix(c(0.5,1,-1,0.3),2,2)
T <- matrix(c(45,-15),2,1)
m.plotImage(c.transformImg(imat, R, T) , kp=c.transformKeys(d.train[15,],R,T))

```

Linear transformation are working okay ... but clearly not enough.

# Using non linear transformation

## Principles and idea

We define a family of transformation Ti : (x,y) -> (x',y') in such a way that :

* Ti : KP.mean -> KP.i
* and (we hope) Ti Img.mean -> Img.i

When looking a a test image, Img.t, we just search for the transformation Tt, so that :

Tt : Im.mean ~ Im.t ( approximately, i.e., having the best correlation coefficient)

When we have found a Tt, we can expect that : Tt(KP.mean) ~ KP.t, QED !

Defining Ti can be done using :

(x,y) -> (1,x,y,xy,x², y²) -> (multiply by a 6x2 matrix) -> (x',y')

Ti is thus defined by 12 coefficients.

To generate all possible Ti, we should ensure that the family is able to generate all the KP.i for the training set from the KP.mean. (~ 2000 transformations) We can then enlarge the transformations set by scaling/rotation/translating/symetry.

We can then pre-compute the value of Ti(Im.mean) for all valid Ti ( 10 000 ?100 000) which we will then have to correlate with Im.t to find the right transformation.

## Computing the tranformation

The transformation is fully defined by the transformation matrix, Tm.

* Tm is a 2x6 matrix
* x and y are scalar
* we get a 2x1 vector as result.

```{r}
t.transform <- function(x,y, Tm) {
X <- c(1,x,y,x*x,y*y,x*y)
return (Tm %*% X)
}
```

Transforming a key point set :

* Tm is 2x6
* kp is 1x30 (keypoint)
* result is 1x30 (vector)

```{r}
t.transformKeys <- function(kp, Tm){
  res <- rep(0,30)
  for(k in seq(1,29,2)) {
    x <- as.numeric(kp[k])
    y <- as.numeric(kp[k+1])
    Y <- t.transform(x,y,Tm)
    res[k] <- Y[1]
    res[k+1] <- Y[2]
  }
  return (res)
}

```

## Solving transformation parameters from the kp

We try to find Tm so that t.transform(kp1,Tm) -> kp2

This can be done using lsfit to fit the various points input(+ intercept + 2nd order terms) to kp2 = y

This returns the matrix Tm, 2x6

```{r}

t.fit <- function(kp1,kp2) {
  kp <- matrix(kp1,15,2, byrow = TRUE)
  Y <- matrix(kp2,15,2,byrow = TRUE)
  X <- matrix(0,15,6)
  X[,1]<- 1
  X[,2] <- kp[,1]
  X[,3] <- kp[,2]
  X[,4] <- kp[,1] ^2
  X[,5] <- kp[,2] ^2
  X[,6] <- kp[,2]*kp[,1]
 
  mod <- lsfit(x=X,y=Y, intercept = FALSE)
  return (t(mod$coefficients))
  }

```

Testing ...

```{r}
k <- sample(1:1000,1)
# Make sure you use as.numeric or you will get strange size errors ...
Tm <- t.fit(as.numeric(d.key.mean), as.numeric(d.train[k,]))
Tm
message ("Max abs error reduction = ",max(abs(t.transformKeys(d.key.mean,Tm) - d.train[k,])) / max(abs(d.key.mean - d.train[k,])) , " should be below 1")

```
Not too bad ...

Let's generate all the transformation related to the d.train data ...

```{r generating training transformation data}
d.transform <- matrix(NA,nrow(d.train),12)
for( k in d.train.complete) {
  d.transform[k,] <- c(t.fit(as.numeric(d.key.mean),as.numeric(d.train[k,])))
}
d.transform.mean <- apply(d.transform,2,mean,na.rm = TRUE)
d.transform.max <- apply(d.transform - d.transform.mean,2,max,na.rm = TRUE)
d.transform.min <- apply(d.transform - d.transform.mean,2,min,na.rm = TRUE)
apply(d.transform,2,hist, breaks=50)
d.transform.min
d.transform.max
d.transform.mean

```


## Applying transformation on an image 

For a test image, we are going to evaluate the correlation between this test image and transformed version of the "mean" image.

We first need to be able to transform an image

* imat is an image in matrix form
* returning an image in matrix form

```{r}
t.transformImg <- function(imat,Tm) {
  imat2 <- matrix(0,nrow(imat),ncol(imat))
  for(x in 1:nrow(imat)){
    for(y in 1:ncol(imat)) {
      Y <- t.transform(x,y,Tm)
      if(all(Y[1] >= 1 & Y[1] <= nrow(imat) & Y[2] >= 1 & Y[2] <= ncol(imat))){
      imat2[x,y] <- c.interpolateImg(imat,Y[1],Y[2])
      }
    }
  }
  return (imat2)
}

```

Testing ... (img transformation works in reverse order)

```{r}
k <- sample(1:1000,1)
Tm <- matrix(d.transform[k,],2,6)
im2 <- t.transformImg(matrix(im.train[k,],96,96),Tm)
kp2 <- t.transformKeys(d.train[k,],Tm)

m.plotImage(im.train[k,], kp=d.train[k,])
title(main="Original")

test <- matrix(NA,10,2)
test[1,1] <- c.corSubImage(im.average,im.train[k,], 25:75,10:30) # mouth
test[2,1] <- c.corSubImage(im.average,im.train[k,], 10:86,50:80) # eyes
test[3,1] <- c.corSubImage(im.average,im.train[k,], 40:60,30:50) # nose
#test[10,1] <- c.corSubImage(im.average,im.train[k,]) # all

m.plotImage(im2, kp=d.key.mean)
title(main="Corrected")

test[1,2]<-c.corSubImage(im.average,im2,25:75,10:30) # mouth
test[2,2]<-c.corSubImage(im.average,im2, 10:86,50:80) # eyes
test[3,2]<-c.corSubImage(im.average,im2, 40:60,30:50) # nose

#test[10,2]<-c.corSubImage(im.average,im2,25:75) # all
test <- as.data.frame(test, row.names = c("mouth","eyes","nose"))
names(test) <- c("Original","Corrected")
test
summary(test)
colSums(test, na.rm = TRUE)


```
Clearly, one need to check correlation with very selective faces areas.

## Another idea :

Match with a few selected, representives faces, normalized (i.e. corrected to have them match the d.key.mean values) and find best transformation using optim, general non linear solver, which can transform the test face into a close version of the corrected reference faces ...

Lets try that.

We first define the function that 'evaluate' the correlation between two images.

```{r}

t.cost<- function(im1,im2) {
  res <- im1 - im2
  res <- res ^2
  return (sum(res) / length(c(im1)))
}

t.evaluate<- function (im1, im2, Tm) {
  Tm <- matrix(Tm,2,6)
  im1 <- matrix(im1, 96,96)
  im2 <- matrix(im2,96,96)
  
  a <- t.cost(im1[20:75,10:30],im2[20:75,10:30]) # mouth
  b <- t.cost(im1[10:86,50:80],im2[10:86,50:80]) # eyes
  c <- t.cost(im1[40:50,30:60],im2[40:50,30:60]) # nose
  d <- t.cost(im1[10:86,10:80],im2[10:86,10:80]) # face
  return (7*a+11*b+13*c+d)
}

```

The following function will try to find the coefficients for the Tm matrix that maximize the correlation between the transformed image and the im.average image.

* input : images vectors or matrix, im1 and im2. Size is assumed to be 96 x 96
* try is the number of random tries to get to the global optimum


```{r}

t.fitImg<-function(im1, im2, try=20){
  im1 <- matrix(im1,96,96)
  im2 <- matrix(im2,96,96)
  bestres <- NULL
  bestcost <- Inf
  for(r in 1:try) {
  par <- runif(12,-0.015,0.015)
  par[3] <- par[3] +1
  par[6] <- par[6] +1
  res <- optim(par=par, fn=function(x) {t.evaluate(im1,im2,x)}, method="BFGS" )
  if(res$value < bestcost) {
    bestcost <- res$value
    bestres <- res
    message("Bestcost = ",bestcost)
  }
  }
  return (matrix(bestres$par,2,6))
}
```

Testing 

```{r}
k <- 22
Tm <- t.fitImg( im.train[k,], im.average, try=20)
Tm

m.plotImage(im.train[k,], kp=d.train[k,], col="red")
m.plotKeypoints(d.key.mean,col = "yellow")
im2 <- t.transformImg(matrix(im.train[k,],96,96),Tm)
m.plotImage(im2, kp=d.key.mean, col="yellow")


```


